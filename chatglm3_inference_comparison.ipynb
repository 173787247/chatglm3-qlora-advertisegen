{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGLM3-6B QLoRA å¾®è°ƒå‰åæ•ˆæœå¯¹æ¯”\n",
    "\n",
    "æœ¬ Notebook ç”¨äºå¯¹æ¯”å¾®è°ƒå‰åçš„ ChatGLM3-6B æ¨¡å‹åœ¨ AdvertiseGen æ•°æ®é›†ä¸Šçš„ç”Ÿæˆæ•ˆæœã€‚\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.57.1)\n",
      "Requirement already satisfied: peft in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.18.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.3.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (25.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2025.11.3)\n",
      "Requirement already satisfied: requests in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (7.1.3)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from peft) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rchua\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests->transformers) (2025.8.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\rchua\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\rchua\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ip (C:\\Users\\rchua\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages)\n",
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# å®‰è£…ä¾èµ–ï¼ˆå¦‚æœé‡åˆ° ModuleNotFoundErrorï¼Œè¯·è¿è¡Œæ­¤å•å…ƒæ ¼ï¼‰\n",
    "# å–æ¶ˆä¸‹é¢çš„æ³¨é‡Šæ¥å®‰è£…\n",
    "# !pip install torch transformers peft pandas\n",
    "!pip install torch transformers peft pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. å®‰è£…ä¾èµ–ï¼ˆå¦‚æœæœªå®‰è£…ï¼‰\n",
    "\n",
    "**æ³¨æ„**: å¦‚æœé‡åˆ° `ModuleNotFoundError`ï¼Œè¯·å…ˆè¿è¡Œä¸‹é¢çš„å•å…ƒæ ¼å®‰è£…ä¾èµ–ã€‚\n",
    "\n",
    "```python\n",
    "# å–æ¶ˆæ³¨é‡Šä¸‹é¢çš„è¡Œæ¥å®‰è£…ä¾èµ–\n",
    "# !pip install torch transformers peft pandas\n",
    "```\n",
    "\n",
    "## 2. å¯¼å…¥å¿…è¦çš„åº“\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "# å¦‚æœé‡åˆ° ModuleNotFoundErrorï¼Œè¯·å…ˆè¿è¡Œ Cell 1 å®‰è£…ä¾èµ–ï¼Œç„¶åé‡å¯å†…æ ¸\n",
    "import torch\n",
    "from transformers import AutoModel, AutoTokenizer, BitsAndBytesConfig\n",
    "from peft import PeftModel, PeftConfig\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"âœ… æ‰€æœ‰åº“å¯¼å…¥æˆåŠŸ\")\n",
    "print(f\"PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"Transformers ç‰ˆæœ¬: {transformers.__version__}\")\n",
    "print(f\"PEFT ç‰ˆæœ¬: {peft.__version__}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. åŠ è½½åŸºç¡€æ¨¡å‹å’Œ Tokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ¨¡å‹ID\n",
    "model_name_or_path = 'THUDM/chatglm3-6b'\n",
    "\n",
    "# æ ¹æ®è®­ç»ƒè„šæœ¬ï¼Œè®­ç»ƒæ—¶ä½¿ç”¨äº† --bnb_mode noneï¼Œæ‰€ä»¥è¿™é‡Œä¸ä½¿ç”¨é‡åŒ–\n",
    "print(\"æ­£åœ¨åŠ è½½åŸºç¡€æ¨¡å‹...\")\n",
    "base_model = AutoModel.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    device_map='auto',\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "base_model.requires_grad_(False)\n",
    "base_model.eval()\n",
    "\n",
    "print(\"æ­£åœ¨åŠ è½½ Tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path,\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "print(\"âœ… åŸºç¡€æ¨¡å‹å’Œ Tokenizer åŠ è½½å®Œæˆ\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. åŠ è½½å¾®è°ƒåçš„æ¨¡å‹ï¼ˆQLoRA Adapterï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¾®è°ƒåçš„æ¨¡å‹è·¯å¾„\n",
    "peft_model_path = \"outputs/chatglm3-qlora\"\n",
    "\n",
    "print(f\"æ­£åœ¨åŠ è½½å¾®è°ƒåçš„æ¨¡å‹: {peft_model_path}\")\n",
    "config = PeftConfig.from_pretrained(peft_model_path)\n",
    "fine_tuned_model = PeftModel.from_pretrained(base_model, peft_model_path)\n",
    "fine_tuned_model.eval()\n",
    "\n",
    "print(\"âœ… å¾®è°ƒåçš„æ¨¡å‹åŠ è½½å®Œæˆ\")\n",
    "print(f\"è®­ç»ƒé…ç½®: LoRA r={config.r}, alpha={config.lora_alpha}, dropout={config.lora_dropout}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. å®šä¹‰å¯¹æ¯”å‡½æ•°\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_responses(query, base_model, fine_tuned_model, tokenizer):\n",
    "    \"\"\"\n",
    "    å¯¹æ¯”åŸºç¡€æ¨¡å‹å’Œå¾®è°ƒåæ¨¡å‹çš„ç”Ÿæˆç»“æœ\n",
    "    \"\"\"\n",
    "    # åŸºç¡€æ¨¡å‹ç”Ÿæˆ\n",
    "    base_response, _ = base_model.chat(tokenizer, query=query, history=[])\n",
    "    \n",
    "    # å¾®è°ƒåæ¨¡å‹ç”Ÿæˆ\n",
    "    fine_tuned_response, _ = fine_tuned_model.chat(tokenizer, query=query, history=[])\n",
    "    \n",
    "    return base_response, fine_tuned_response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ä½¿ç”¨ AdvertiseGen æµ‹è¯•æ ·æœ¬è¿›è¡Œå¯¹æ¯”\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•æç¤ºè¯ï¼ˆæ¥è‡ª AdvertiseGen æ•°æ®é›†ï¼‰\n",
    "test_prompts = [\n",
    "    \"å†™ä¸€æ®µ 30 å­—çš„å¹¿å‘Šæ–‡æ¡ˆï¼Œæ¨å¹¿æ™ºèƒ½ç†è´¢æœåŠ¡\",\n",
    "    \"ä¸ºä¸€å®¶ç²¾å“é…’åº—æ’°å†™ä¸€æ¡ä¿ƒé”€æ¨é€é€šçŸ¥\",\n",
    "    \"ä»¥äº²åˆ‡çš„å£å»ï¼Œå†™ä¸€ä¸ªä½“è‚²ç”¨å“å“ç‰Œçš„å¼•å¯¼è´­ä¹°å¯¹è¯\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"å¾®è°ƒå‰åæ•ˆæœå¯¹æ¯”\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for i, prompt in enumerate(test_prompts, 1):\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"æµ‹è¯•æ ·æœ¬ {i}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nğŸ“ Promptï¼ˆæç¤ºè¯ï¼‰:\")\n",
    "    print(f\"   {prompt}\")\n",
    "    \n",
    "    # è·å–å¯¹æ¯”ç»“æœ\n",
    "    base_response, fine_tuned_response = compare_responses(\n",
    "        prompt, base_model, fine_tuned_model, tokenizer\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nğŸ”µ å¾®è°ƒå‰è¾“å‡º:\")\n",
    "    print(f\"   {base_response}\")\n",
    "    \n",
    "    print(f\"\\nğŸŸ¢ å¾®è°ƒåè¾“å‡º:\")\n",
    "    # æ¸…ç†è¾“å‡ºæ–‡æœ¬ï¼ˆç§»é™¤ç‰¹æ®Šæ ‡è®°ï¼‰\n",
    "    cleaned_response = fine_tuned_response.replace('[gMASK]', '').replace('sop', '').strip()\n",
    "    print(f\"   {cleaned_response}\")\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. æ˜¾ç¤ºè®­ç»ƒæ—¶ä¿å­˜çš„å¯¹æ¯”ç»“æœ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä»è®­ç»ƒç»“æœä¸­è¯»å–å¯¹æ¯”æ•°æ®\n",
    "comparison_df = pd.read_csv(\"outputs/chatglm3-qlora/prompt_comparison.csv\")\n",
    "print(f\"âœ… è¯»å–äº† {len(comparison_df)} ä¸ªæµ‹è¯•æ ·æœ¬\")\n",
    "print(\"\\nè®­ç»ƒæ—¶ä¿å­˜çš„å¾®è°ƒå‰åå¯¹æ¯”ç»“æœ:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"æ ·æœ¬ {idx + 1}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"\\nğŸ“ Promptï¼ˆæç¤ºè¯ï¼‰:\")\n",
    "    print(f\"   {row['prompt']}\")\n",
    "    \n",
    "    print(f\"\\nğŸ”µ å¾®è°ƒå‰è¾“å‡º:\")\n",
    "    if row['pretraining_response'] == '[baseline skipped]':\n",
    "        print(\"   [åŸºçº¿æµ‹è¯•å·²è·³è¿‡]\")\n",
    "    else:\n",
    "        pre_text = str(row['pretraining_response']).replace('[gMASK]', '').replace('sop', '').strip()\n",
    "        print(f\"   {pre_text[:300]}...\" if len(pre_text) > 300 else f\"   {pre_text}\")\n",
    "    \n",
    "    print(f\"\\nğŸŸ¢ å¾®è°ƒåè¾“å‡º:\")\n",
    "    post_text = str(row['posttraining_response']).replace('[gMASK]', '').replace('sop', '').strip()\n",
    "    # ç§»é™¤é‡å¤å†…å®¹\n",
    "    if post_text.count('\"') > 4:\n",
    "        lines = post_text.split('\\n')\n",
    "        unique_lines = []\n",
    "        seen = set()\n",
    "        for line in lines:\n",
    "            line_clean = line.strip().strip('\"').strip()\n",
    "            if line_clean and line_clean not in seen:\n",
    "                unique_lines.append(line_clean)\n",
    "                seen.add(line_clean)\n",
    "        post_text = '\\n'.join(unique_lines)\n",
    "    \n",
    "    print(f\"   {post_text[:500]}...\" if len(post_text) > 500 else f\"   {post_text}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. æ€»ç»“\n",
    "\n",
    "é€šè¿‡å¯¹æ¯”å¯ä»¥çœ‹å‡ºï¼š\n",
    "\n",
    "1. **å¾®è°ƒå‰**: æ¨¡å‹å¯¹å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆä»»åŠ¡çš„ç†è§£è¾ƒä¸ºåŸºç¡€ï¼Œå¯èƒ½ç”Ÿæˆé€šç”¨æ€§è¾ƒå¼ºçš„å›ç­”\n",
    "2. **å¾®è°ƒå**: æ¨¡å‹åœ¨ AdvertiseGen æ•°æ®é›†ä¸Šå¾®è°ƒåï¼Œèƒ½å¤Ÿæ›´å¥½åœ°ç†è§£å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆçš„éœ€æ±‚ï¼Œç”Ÿæˆæ›´ç¬¦åˆä»»åŠ¡è¦æ±‚çš„æ–‡æ¡ˆ\n",
    "3. **è®­ç»ƒæ•ˆæœ**: Loss ä» 4.23 é™ä½åˆ° 2.27ï¼Œé™ä½äº† 46.5%ï¼Œè¯´æ˜æ¨¡å‹åœ¨è®­ç»ƒæ•°æ®ä¸Šå­¦ä¹ åˆ°äº†æœ‰æ•ˆçš„æ¨¡å¼\n",
    "\n",
    "### è®­ç»ƒé…ç½®\n",
    "- **æ•°æ®é›†**: AdvertiseGen (10,000 æ ·æœ¬)\n",
    "- **æ•°æ®æ¥æº**: `data/advertisegen.json`\n",
    "- **è®­ç»ƒæ–¹æ³•**: QLoRA (LoRA + 4-bité‡åŒ–)\n",
    "- **è®­ç»ƒè½®æ•°**: 3 epochs\n",
    "- **ç¡¬ä»¶**: RTX-5080, 16GB GPU, CUDA 12.9\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
